{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0dfa36827463457e711ee0f6313e71839a6e74b4e10eee05d0ef1d4d260e6136b",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "dfa36827463457e711ee0f6313e71839a6e74b4e10eee05d0ef1d4d260e6136b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "from einops import rearrange\n",
    "from common import *\n",
    "from models.vt_resnet18 import VTResNet18\n",
    "from TinyImageNet import TinyImageNet\n",
    "from models.resnet import BasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\dmele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\transforms\\transforms.py:1200: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_IMAGE_NET = \"./data/tiny-imagenet-200\"\n",
    "BATCH_SIZE_TRAIN = 100\n",
    "BATCH_SIZE_VAL = 100\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "transform_train = torchvision.transforms.Compose(\n",
    "     [torchvision.transforms.RandomHorizontalFlip(),\n",
    "     torchvision.transforms.RandomRotation(10, resample=PIL.Image.BILINEAR),\n",
    "     torchvision.transforms.RandomAffine(8, translate=(.15,.15)),\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "\n",
    "transform_val = torchvision.transforms.Compose([\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "train_dataset = TinyImageNet(PATH_TO_IMAGE_NET, split='train', transform=transform_train, in_memory=False)\n",
    "val_dataset = TinyImageNet(PATH_TO_IMAGE_NET, split='val', transform=transform_val, in_memory=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE_VAL, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1\n",
      "[    0/100000 (  0%)]  Loss: 5.2792\n",
      "[10000/100000 ( 10%)]  Loss: 5.4081\n",
      "[20000/100000 ( 20%)]  Loss: 5.3046\n",
      "[30000/100000 ( 30%)]  Loss: 5.3871\n",
      "[40000/100000 ( 40%)]  Loss: 5.3224\n",
      "[50000/100000 ( 50%)]  Loss: 5.2932\n",
      "[60000/100000 ( 60%)]  Loss: 5.2927\n",
      "[70000/100000 ( 70%)]  Loss: 5.2966\n",
      "[80000/100000 ( 80%)]  Loss: 5.3424\n",
      "[90000/100000 ( 90%)]  Loss: 5.3025\n",
      "Execution time: 455.80 seconds\n",
      "\n",
      "Average train loss: 5.3001\n",
      "\n",
      "Train accuracy: 0.7840\n",
      "\n",
      "Average test loss: 5.2903\n",
      "\n",
      "Test accuracy: 0.9300\n",
      "Execution time\n"
     ]
    }
   ],
   "source": [
    "model = VTResNet18(\n",
    "    resnet_block=BasicBlock,\n",
    "    layers=[2, 2, 2, 2], \n",
    "    tokens=16,\n",
    "    token_channels=128,\n",
    "    input_dim=224,\n",
    "    layer_channels=[64, 128, 256, 512],\n",
    "    num_classes=200\n",
    "\n",
    ")\n",
    "model = model.to(device)\n",
    "EPOCHS = 1\n",
    "check_on_dataset(model, train_loader, val_loader, EPOCHS, \"TinyImageNet\", \"fixed_ViTResNet18\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}