{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0dfa36827463457e711ee0f6313e71839a6e74b4e10eee05d0ef1d4d260e6136b",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "dfa36827463457e711ee0f6313e71839a6e74b4e10eee05d0ef1d4d260e6136b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "from torch import nn\n",
    "import torch.nn.init as init\n",
    "from ViTResNet18_remastered import *\n",
    "from common import *\n",
    "from TinyImageNet import TinyImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_IMAGE_NET = \"./data/tiny-imagenet-200\"\n",
    "BATCH_SIZE_TRAIN = 100\n",
    "BATCH_SIZE_VAL = 100\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "transform_train = torchvision.transforms.Compose(\n",
    "     [torchvision.transforms.RandomHorizontalFlip(),\n",
    "     torchvision.transforms.RandomRotation(10, resample=PIL.Image.BILINEAR),\n",
    "     torchvision.transforms.RandomAffine(8, translate=(.15,.15)),\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "\n",
    "transform_val = torchvision.transforms.Compose([\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "train_dataset = TinyImageNet(PATH_TO_IMAGE_NET, split='train', transform=transform_train, in_memory=False)\n",
    "val_dataset = TinyImageNet(PATH_TO_IMAGE_NET, split='val', transform=transform_val, in_memory=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE_VAL, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model = ViTResNet18(BasicBlock, [2, 2, 2], BATCH_SIZE_TRAIN, num_classes=200, num_tokens=16, ).to(device)\n",
    "EPOCHS = 90\n",
    "check_on_dataset(model, train_loader, val_loader, EPOCHS, \"TinyImageNet\", \"ViTResNet18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "model = ViTResNet18(BasicBlock, [2, 2, 2], BATCH_SIZE_TRAIN, num_classes=200,\n",
    "                    num_tokens=16, tokenizers_type=['pooling', 'pooling']).to(device)\n",
    "EPOCHS = 90\n",
    "check_on_dataset(model, train_loader, val_loader, EPOCHS, \"TinyImageNet\", \"ViTResNet18(pooling)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_IMAGE_NET = \"./data/tiny-imagenet-201\"\n",
    "BATCH_SIZE_TRAIN = 100\n",
    "BATCH_SIZE_VAL = 100\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "transform_train = torchvision.transforms.Compose(\n",
    "     [torchvision.transforms.RandomHorizontalFlip(),\n",
    "     torchvision.transforms.RandomRotation(10, resample=PIL.Image.BILINEAR),\n",
    "     torchvision.transforms.RandomAffine(8, translate=(.15,.15)),\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "\n",
    "transform_val = torchvision.transforms.Compose([\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "train_dataset = TinyImageNet(PATH_TO_IMAGE_NET, split='train', transform=transform_train, in_memory=False)\n",
    "val_dataset = TinyImageNet(PATH_TO_IMAGE_NET, split='val', transform=transform_val, in_memory=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE_VAL, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "model = model = ViTResNet18(BasicBlock, [2, 2, 2], BATCH_SIZE_TRAIN, num_classes=200, num_tokens=16).to(device)\n",
    "EPOCHS = 90\n",
    "check_on_dataset(model, train_loader, val_loader, EPOCHS, \"TinyImageNet(64x64)\", \"ViTResNet18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_IMAGE_NET = \"./data/tiny-imagenet-200\"\n",
    "BATCH_SIZE_TRAIN = 100\n",
    "BATCH_SIZE_VAL = 100\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "transform_train = torchvision.transforms.Compose(\n",
    "     [torchvision.transforms.RandomHorizontalFlip(),\n",
    "     torchvision.transforms.RandomRotation(10, resample=PIL.Image.BILINEAR),\n",
    "     torchvision.transforms.RandomAffine(8, translate=(.15,.15)),\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "\n",
    "transform_val = torchvision.transforms.Compose([\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "train_dataset = TinyImageNet(PATH_TO_IMAGE_NET, split='train', transform=transform_train, in_memory=False)\n",
    "val_dataset = TinyImageNet(PATH_TO_IMAGE_NET, split='val', transform=transform_val, in_memory=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE_VAL, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTResNet18(BasicBlock, [2, 2, 2], BATCH_SIZE_TRAIN, num_classes=200,\n",
    "                    num_tokens=16, tokenizers_type=['filter', 'recurrent']).to(device)\n",
    "EPOCHS = 90\n",
    "check_on_dataset(model, train_loader, val_loader, EPOCHS, \"TinyImageNet\", \"ViTResNet18(recurrent)\")"
   ]
  }
 ]
}